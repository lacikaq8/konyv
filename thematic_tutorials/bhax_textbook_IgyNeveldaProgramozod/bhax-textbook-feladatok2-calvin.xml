<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.0" xml:lang="hu">
    <info>
        <title>Helló, Calvin!</title>
        <keywordset>
            <keyword/>
        </keywordset>
    </info>

    <section>
        <title>MNIST</title>
        <para>
            Az alap feladat megoldása, +saját kézzel rajzolt képet is ismerjen fel,
            <link xlink:href="https://progpater.blog.hu/2016/11/13/hello_samu_a_tensorflow-bol">https://progpater.blog.hu/2016/11/13/hello_samu_a_tensorflow-bol</link> Háttérként ezt vetítsük le:
            https://prezi.com/0u8ncvvoabcr/no-programming-programming/
        </para>
        <para>
            Megoldás videó:
        </para>
        <para>
            Megoldás forrása:                
        </para>
        <para>
            <emphasis role="strong">Tanulságok, tapasztalatok, magyarázat...</emphasis>
        </para>
        <para>
            Az MNIST egy olyan program mely egy előre elkészült kézzel rajzolt számok képadatbázisból
            megtanítja magát hogy felismerje azokat.A program python nyelven írodott és a tensorflowra könyvtárhoz is szükségünk van
            Mi is az a tensorflow? Google Brain team által létrehozott library melyben machine learning és deep learning modelleket és algoritmusokat találunk.
        </para>
        <para>
            Elsőnek importáljuk a tanításhoz szükséges mintákat adatbázist.
            <programlisting>
            from tensorflow.examples.tutorials.mnist import input_data
            </programlisting>
            Elsőnek deklarálunk egy függvény mely majd beolvassa a custom képünket.A file abban adhatjuk meg
            a custom képünk nevét. Majd a beadott képet dekódoljuk uint8 vagy uint16 ra.
            <programlisting>
                def readimg():
                file = tf.io.read_file("egytizes.png")
                img = tf.image.decode_png(file,channels=1)
                return img
            </programlisting>
            Most olvassuk be a képeket az <varname>x</varname> nem egy konkrét érték lesz hanem egy placehorder
            jelen esetben a mi modellunk 2D-s lesz és 784 dimenziós vektorú. A <varname>w</varname> az egy variable tipusú ami
            csak annyit jelenet hogy módosítható tensor és ez tárolja a súlyokat. <varname>b</varname> is variable tipusú csak ebben
            az eltolási értéket tároljuk. <varname>y</varname>-ba összeszorozzuk a <varname>x</varname> <varname>w</varname> matrixokat (784x10)
            és hozzadjuk a <varname>b</varname>-t így kapunk egy 10 dimenziójú vektort.
            <programlisting>
            mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)
                # Create the model
                x = tf.placeholder(tf.float32, [None, 784])
                W = tf.Variable(tf.zeros([784, 10]))
                b = tf.Variable(tf.zeros([10]))
                y = tf.matmul(x, W) + b
            </programlisting>
            Az <varname>y</varname>-ba fogjuk tárolni az általunk kiszámított
            eloszlásokat, míg az <varname>y_</varname>-ban a valódi eloszlást.
            <programlisting>
            y_ = tf.placeholder(tf.float32, [None, 10])
            </programlisting>
            Ezután szükségünk lesz egy indicátorra hogy tesztelni tudjuk a modellt hogy mennyire rossz
            a célunk az hogy ezt minimalizáljuk. A tf.nn.softmax_cross_entropy_with_logits kiszámolja a cross entropyt
            <varname>y</varname> <varname>y_</varname> között. A tf.reduce_mean meg kiszámolja az átlagot.
            tf.train.GradientDescentOptimizer használjuk hogy csökkentük az átlagos veszteséget 0.5 benne annyit adjatunk meg mekkora egységekkel közelítsük meg jelen esetben 0.5.
            <programlisting>
            cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y,labels=y_))
            train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
            </programlisting>
            Itt inicializálja változóinkat és elinítunk egy sessiont.
            <programlisting >
            sess = tf.InteractiveSession()
            tf.initialize_all_variables().run(session=sess)
            </programlisting>
            Itt folyik maga a tanítás 1000x fut el és mindel alkalommal kiválaszt random 100 elemet az adatbázisból. Itt újra <varname>y_</varname> <varname>y</varname>
            kiszámítjuk értékeket majd ezzel kiszámoljuk a átlagos vesztegéget és minimalizáljuk.
            <programlisting>
            for i in range(1000):
            batch_xs, batch_ys = mnist.train.next_batch(100)
            sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
            if i % 100 == 0:
            print(i/10, "%")
            </programlisting>
            Most hogy a tanítással megvagyunk teszteljük. tf.argmax megadja egy adott tengelyen a legnagyobb indexet és ha ez 2 megegyezik akkor helyesen tippeltünk.
            A tf.cast átalakítja az igazságértékünket float 32-re.Ezután kiszámpljuk mennyire pontos a model.
            <programlisting>
            correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))  
            print("-- Pontossag: ", sess.run(accuracy, feed_dict={x: mnist.test.images,y_: mnist.test.labels}))   
            </programlisting> 
        </para>
    </section>        

    <section>
        <title>Deep MNIST</title>
        <para>
            Mint az előző, de a mély változattal. Segítő ábra, vesd össze a forráskóddal a
            <link xlink:href="https://arato.inf.unideb.hu/batfai.norbert/NEMESPOR/DE/denbatfai2.pdf">https://arato.inf.unideb.hu/batfai.norbert/NEMESPOR/DE/denbatfai2.pdf</link> 8. fóliáját!
        </para>
        <para>
            Megoldás videó:
        </para>
        <para>
            Megoldás forrása:                
        </para>
        <para>
           <emphasis role="strong">Tanulságok, tapasztalatok, magyarázat...</emphasis>
        </para>
        <para>
            Sima mnistel-el 90-92% pontosságokat kaptunk ami papíron elég jól néz ki de a valóságban ez az eredmény gyenge. Feladatunk ugyanaz mint az előzőbe csak a deep mnistbe kell megvalósítani
            ami annyit jelent hogy pontosabb értékek létrehozásáért neurális hálókat is behozunk a programunkba.
        </para>
        <para>
            Létrehozzuk deepnn-t ahol a képek átalakítjuk.
            <programlisting>
                def deepnn(x):
                with tf.name_scope('reshape'):
                x_image = tf.reshape(x, [-1, 28, 28, 1])
            </programlisting>
                <varname>W_conv1</varname> fogja tartalmazni a súlyokat melynek az alakja [5, 5, 1, 32] ebben az első kettő a kép alakját írja le a harmadik a bemeneti streamet 4. pedig ki streamet.
                Így azt kaptuk hogy minden 5x5 képhez 32 db összeget fog kiszámítani. <varname>b_conv1</varname> tárolunk 32 bias-t. Majd összeszorozzuk az értékeinket, A tf.nn.relu az pedig ha negatív
                értéke van 0 ad vissza ha pedig pozitív akkor magát a számot.
            <programlisting>
                with tf.name_scope('conv1'):
                W_conv1 = weight_variable([5, 5, 1, 32])
                b_conv1 = bias_variable([32])
                h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)

                with tf.name_scope('pool1'):
                h_pool1 = max_pool_2x2(h_conv1
            </programlisting>
                Mivel neurális hálót készítünk több mint egy rétegre lesz szükségünk. A második réteget az elsőből számoljuk ki. Itt már a súlyunk 32 bemenetet kap és 64-eset ad vissza. Szóval itt már minden 5x5 képhez 64 összeget számol ki.
            <programlisting>
                with tf.name_scope('conv2'):
                W_conv2 = weight_variable([5, 5, 32, 64])
                b_conv2 = bias_variable([64])
                h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
                with tf.name_scope('pool2'):
                h_pool2 = max_pool_2x2(h_conv2)
            </programlisting>
                Ezután egy 1024 neuronból álló fc réteget adunk hozzá a modellhez itt fel is dolgozzuk az egész képet.
                Kiszámoljuk a súlyokat és a biasokat majd a tf.reshape függvénnyel egy mátrixá alakítjuk a h.pool2-tőt. Majd ezt a mátrixot
                megszorozzuk a <varname>w_fci</varname> mátrixal és hozzáadjuk a <varname>b_fc1</varname> mátrixot majd odaadjuk a tf.nn.relu-nak
            <programlisting>
                with tf.name_scope('fc1'):
                W_fc1 = weight_variable([7 * 7 * 64, 1024])
                b_fc1 = bias_variable([1024])

                h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
                h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)  
            </programlisting>
                Itt a fölösleges neuronokat eldobjuk és létrehozunk egy placeholdert.
            <programlisting>
                with tf.name_scope('dropout'):
                keep_prob = tf.placeholder(tf.float32)
                h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)  
            </programlisting>
                Ez lesz szoftmax réteg
            <programlisting>
                ith tf.name_scope('fc2'):
                W_fc2 = weight_variable([1024, 10])
                b_fc2 = bias_variable([10])

                y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2
                return y_conv, keep_prob
            </programlisting>
                A conv2d 4D-s inputból és szűrőbből egy 2D-s konvolúciót számol ki és visszaadja.
            <programlisting>
                def conv2d(x, W):
                """conv2d returns a 2d convolution layer with full stride."""
                return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
    
                def max_pool_2x2(x):
                """max_pool_2x2 downsamples a feature map by 2X."""
                return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                strides=[1, 2, 2, 1], padding='SAME')
  
            </programlisting>
                Itt súly számolunk az alakból.A bias generálunk a shapeből.És az öreg readimg-be meg beolvassuk a saját képünket.
            <programlisting>
                def weight_variable(shape):
  """weight_variable generates a weight variable of a given shape."""
  initial = tf.compat.v1.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)


def bias_variable(shape):
  """bias_variable generates a bias variable of a given shape."""
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)

def readimg():
  file = tf.compat.v1.read_file("asd4.png")
  img = tf.image.decode_png(file, 1)
  return img
            </programlisting>
        </para>

    </section>        
        
    <section>
        <title>
            <emphasis role="cadiumgreen">CIFAR-10</emphasis>
        </title>
        <para>
            Az alap feladat megoldása, +saját fotót is ismerjen fel,
            <link xlink:href="https://progpater.blog.hu/2016/12/10/hello_samu_a_cifar-10_tf_tutorial_peldabol">https://progpater.blog.hu/2016/12/10/hello_samu_a_cifar-10_tf_tutorial_peldabol</link>
        </para>
        <para>
            Megoldás videó:
        </para>
        <para>
            Megoldás forrása:                
        </para>
        <para>
           <emphasis role="strong">Tanulságok, tapasztalatok, magyarázat...</emphasis>
        </para>
    </section>        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
    <section>
        <title>Android telefonra a TF objektum detektálója</title>
        <para>
            Telepítsük fel, próbáljuk ki!
        </para>
        <para>
            Megoldás videó:
        </para>
        <para>
            Megoldás forrása:                
        </para>
        <para>
           <emphasis role="strong">Tanulságok, tapasztalatok, magyarázat...</emphasis>
        </para>
        <para>
            Linkek:
            <link xlink:href="https://developer.android.com/studio/run/device">Developer Optinok bekapcsolása</link>,
            <link xlink:href="https://developer.android.com/studio">Android Studio</link>,
            <link xlink:href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android">tensorflow repó</link>.
        </para>
        <para>
            Elöfeltételek:
        </para>
        <itemizedlist>
            <listitem>
                <para>Kell az Android Studio</para>           
            </listitem>
            <listitem>
                <para>Kell egy androidos készülék és fejlesztői környezet melyek min api 21-esek</para>           
            </listitem>
            <listitem>
                <para>Android Studionak 3.2 vagy újabb verziójúnak kell lenni</para>           
            </listitem>
        </itemizedlist>
        <para>
            Építése:
        </para>
        <itemizedlist>
            <listitem>
                <para>1. Nyissuk meg az android studiot és válaszuk ki a Open an existing Android Studio project</para>          
            </listitem>
            <listitem>
                <para>2. válasszuk ki azt a mappát ahova leclonoltuk a TensorFlow Lite sample GitHub repót</para>           
            </listitem>
            <listitem>
                <para>3. Ha megkérdezni akarunk e Gradle Sync nyumjunk ok-ra</para>           
            </listitem>
            <listitem>
                <para>4. Ha hibákat ad ki hiányoznak key könyvtárak csak telepitsük azokat</para>           
            </listitem>
            <listitem>
                <para>5. Csatlakoztassuk a telefonunkat a számítógéphez(készüléken be kell kapcsolni a developer optiont) </para>           
            </listitem>
            <listitem>
                <para>6. Futassuk :) </para>           
            </listitem>
        </itemizedlist>
    </section>        

    <section>
        <title>SMNIST for Machines</title>
        <para>
            Készíts saját modellt, vagy használj meglévőt, lásd: <link xlink:href="https://arxiv.org/abs/1906.12213">https://arxiv.org/abs/1906.12213</link>
        </para>
        <para>
            Megoldás videó:
        </para>
        <para>
            Megoldás forrása:                
        </para>
        <para>
           <emphasis role="strong">Tanulságok, tapasztalatok, magyarázat...</emphasis>
        </para>
    </section>        

    <section>
        <title>Minecraft MALMO-s példa</title>
        <para>
            A <link xlink:href="https://github.com/Microsoft/malmo">https://github.com/Microsoft/malmo</link> felhasználásával egy ágens példa, lásd pl.:
        </para>
        <para>
            <link xlink:href="https://youtu.be/bAPSu3Rndi8">https://youtu.be/bAPSu3Rndi8</link>,
        </para>
        <para>
            <link xlink:href="https://bhaxor.blog.hu/2018/11/29/eddig_csaltunk_de_innentol_mi">https://bhaxor.blog.hu/2018/11/29/eddig_csaltunk_de_innentol_mi</link>,
        </para>
        <para>
            <link xlink:href="https://bhaxor.blog.hu/2018/10/28/minecraft_steve_szemuvege">https://bhaxor.blog.hu/2018/10/28/minecraft_steve_szemuvege</link>
        </para>
        <para>
            Megoldás videó:
        </para>
        <para>
            Megoldás forrása:                
        </para>
        <para>
           <emphasis role="strong">Tanulságok, tapasztalatok, magyarázat...</emphasis>
        </para>
        <para>
            Minecraft MALMO egy minecraft amibe lehet pyhton c, c++, és java kóddal irányítani a karaktert es alakítani a világot főleg AI fejlesztésre használják. Ezeken
            kívül készíthtünk mission-öket az elobb felsorolt programozasi nyelveken.
        </para>
        <para>Windows-on való telepítése:</para>
        <para>Előszer 3 dolog kell: JDK 8.0 telepítése ,Python 3.6 telepít, zip letöltése és kicsomagolása</para>
        <para>2 módszer van a letöltésre</para>
        <para>Githubról letöltjük az egész mappát</para>
        <para>Vagy powershellbe bizonyos parancsokkal</para>
        <para>2-es módszernél telepítéséhez ezeket kell beírni</para>
        <programlisting>
            <![CDATA[
            Set-ExecutionPolicy -Scope CurrentUser Unrestricted | Engedélyezzük a powershellnek külsős progok telepítését
            cd ahova kicsomagoltad\Malmo-0.35.6-Windows-64bit_Python3.6\scripts
            .\malmo_install.ps1
            ]]>
        </programlisting>
        <para>Ezzel kész is minecraft elindításához ezt kell beírni</para>
        <programlisting>
            <![CDATA[
            cd ahol ki lett csomagolva\Malmo-0.37.0-Windows-64bit_withBoost_Python3.6\Minecraft
            .\launchclient
            ]]>
        </programlisting>
        <para>Ezzel el is indul a minecraft nem kell várni hogy a számláló 100% üssön 95% már indul és sose éri el a 100-at</para>
        <para>És mondjuk egy missiont akarunk indítani python nyelvben</para>
        <programlisting>
            <![CDATA[
            cd ahol ki lett csomagolva\Malmo-0.37.0-Windows-64bit_withBoost_Python3.6\Python_Examples
            python tutorial_1.py
            ]]>
        </programlisting>
        <para>Ezzel letesz minket a jaték egy szerver alapu világba és 10 másodpercig egyhelyben állunk ennél vannak izgalmasabb küldetések is 
        de csak eddig jutottam</para>
        <para>Pár alap parancs</para>
        <programlisting>
            <![CDATA[
            !! az 1 az truera állítja így folyamatosan csinálja a 0 falsera azzal leállítjuk.
            agent_host.sendCommand("turn -0.5") | fordulás
            agent_host.sendCommand("move 1") | előre mozgás 
            agent_host.sendCommand("jump 1") | ugrás
            agent_host.sendCommand("pitch 1") | sötétség
            time.sleep(1) | alvás
            agent_host.sendCommand("attack 1") | támadás
            ]]>
        </programlisting>
    </section>    

    <section>
        <title>EPAM: Reaktív programozás</title>
        <para>
            Számoljuk ki az első 10 nem negatív egész szám összegét és áltagát.
        </para>
    </section>  

    <section>
        <title>EPAM: Back To The Future</title>
        <para>
            Adott az alábbi kódrészlet:
            <programlisting language="java"><![CDATA[
public class FutureChainingExercise {
private static ExecutorService executorService = Executors.newFixedThreadPool(2);
public static void main(String[] args) {
CompletableFuture<String> longTask
= CompletableFuture.supplyAsync(() -> {
sleep(1000);
return "Hello";
}, executorService);
CompletableFuture<String> shortTask
= CompletableFuture.supplyAsync(() -> {
sleep(500);
return "Hi";
}, executorService);
CompletableFuture<String> mediumTask
= CompletableFuture.supplyAsync(() -> {
sleep(750);
return "Hey";
}, executorService);
CompletableFuture<String> result
= longTask.applyToEitherAsync(shortTask, String::toUpperCase, executorService);
result = result.thenApply(s -> s + " World");
CompletableFuture<Void> extraLongTask
= CompletableFuture.supplyAsync(() -> {
sleep(1500);
return null;
}, executorService);
result = result.thenCombineAsync(mediumTask, (s1, s2) -> s2 + ", " +
s1, executorService);
System.out.println(result.getNow("Bye"));
sleep(1500);
System.out.println(result.getNow("Bye"));
result.runAfterBothAsync(extraLongTask, () -
> System.out.println("After both!"), executorService);
result.whenCompleteAsync((s, throwable) -> System.out.println("Complete: " +
s), executorService);
executorService.shutdown();
}
/**
*
* @param sleeptime sleep time in milliseconds
*/
private static void sleep(int sleeptime) {...}
}
        1]]>
            </programlisting>
            Mi lesz kiíratva a standard kimenetre és miért?
        </para>
    </section>  

    <section>
        <title>EPAM: AOP</title>
        <para>
            Készíts két példa projektet, melyben egyes metódusok futási idejét méred majd kiíratod úgy, hogy a metódus
         futási idejének méréséhez AOP-t használsz. Az első projektben csak az AspectJ könyvtárat, a második
        esetében pedig Spring AOP-t használj.
        </para>
    </section>     

</chapter>                
